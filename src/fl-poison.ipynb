{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a189859",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hkasyap/anaconda3/envs/rev/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import asyncio, nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import copy, os, socket, sys, time\n",
    "from functools import partial\n",
    "from multiprocessing import Pool, Process\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), \"../\")))\n",
    "from libs import agg, data, fl, log, nn, plot, poison, resnet, sim, wandb\n",
    "from cfgs.fedargs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e7e0cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-15 18:58:35,908 - Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving. [MainProcess : MainThread (ERROR)]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/hkasyap/Desktop/ATI/fl/libs/../out/wandb/run-20231015_185842-98qlv9s2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kasyah/fl-bias/runs/98qlv9s2' target=\"_blank\">fedval-cnn-mnist-cosine_attack</a></strong> to <a href='https://wandb.ai/kasyah/fl-bias' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kasyah/fl-bias' target=\"_blank\">https://wandb.ai/kasyah/fl-bias</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kasyah/fl-bias/runs/98qlv9s2' target=\"_blank\">https://wandb.ai/kasyah/fl-bias/runs/98qlv9s2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "project = 'fl-bias'\n",
    "name = 'fedval-cnn-mnist-cosine_attack'\n",
    "\n",
    "#Define Custom CFGs\n",
    "fedargs.epochs = 21\n",
    "fedargs.num_clients = 10\n",
    "fedargs.dataset = \"fmnist\"\n",
    "fedargs.agg_rule = agg.Rule.FLTrust\n",
    "\n",
    "FLTrust[\"is\"] = True\n",
    "FLTrust[\"proxy\"][\"is\"] = True\n",
    "\n",
    "cosine_attack[\"is\"] = True\n",
    "cosine_attack[\"kn\"] = poison.Knowledge.IN\n",
    "mal_clients = [c for c in range(4)]\n",
    "\n",
    "# Save Logs To File (info | debug | warning | error | critical) [optional]\n",
    "log.init(\"info\")\n",
    "wb = wandb.init(name, project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bb399c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device settings\n",
    "use_cuda = fedargs.cuda and torch.cuda.is_available()\n",
    "torch.manual_seed(fedargs.seed)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "kwargs = {\"num_workers\": 1, \"pin_memory\": True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76542fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare clients\n",
    "host = socket.gethostname()\n",
    "clients = [host + \"(\" + str(client + 1) + \")\" for client in range(fedargs.num_clients)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "402306c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Global and Client models\n",
    "global_model = copy.deepcopy(fedargs.model)\n",
    "# Load Data to clients\n",
    "train_data, test_data = data.load_dataset(fedargs.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca573ed",
   "metadata": {},
   "source": [
    "<h2>FLTrust</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbe42e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "if FLTrust[\"is\"]:\n",
    "    train_data, FLTrust[\"data\"] = data.random_split(train_data, FLTrust[\"ratio\"])\n",
    "    FLTrust[\"loader\"] = torch.utils.data.DataLoader(FLTrust[\"data\"], batch_size=len(FLTrust[\"data\"]), shuffle=True, **kwargs)\n",
    "    \n",
    "    if FLTrust[\"proxy\"][\"is\"]:\n",
    "        FLTrust[\"data\"], FLTrust[\"proxy\"][\"data\"] = data.random_split(FLTrust[\"data\"], FLTrust[\"proxy\"][\"ratio\"])\n",
    "        FLTrust[\"loader\"] = torch.utils.data.DataLoader(FLTrust[\"data\"], batch_size=fedargs.client_batch_size, shuffle=True, **kwargs)\n",
    "        FLTrust[\"proxy\"][\"loader\"] = torch.utils.data.DataLoader(FLTrust[\"proxy\"][\"data\"], batch_size=fedargs.client_batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8025440b",
   "metadata": {},
   "source": [
    "<h2>Prepare a backdoored loader for test</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "769acb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "if backdoor_attack[\"is\"]:\n",
    "    train_data, backdoor_attack[\"data\"] = data.random_split(train_data, backdoor_attack[\"ratio\"])\n",
    "    backdoor_attack[\"data\"] = poison.insert_trojan(backdoor_attack[\"data\"],\n",
    "                                                   backdoor_attack[\"target_label\"],\n",
    "                                                   backdoor_attack[\"trojan_func\"], 1)\n",
    "    backdoor_attack[\"loader\"] = torch.utils.data.DataLoader(backdoor_attack[\"data\"], batch_size=fedargs.client_batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f568d4",
   "metadata": {},
   "source": [
    "<h2>Load client's data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80508740",
   "metadata": {},
   "outputs": [],
   "source": [
    "clients_data = data.split_data(train_data, clients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87aacd7b",
   "metadata": {},
   "source": [
    "<h2>HDC DP Attack</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c15880d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def background(f):\n",
    "    def wrapped(*args, **kwargs):\n",
    "        return asyncio.get_event_loop().run_in_executor(None, f, *args, **kwargs)\n",
    "\n",
    "    return wrapped\n",
    "\n",
    "@background\n",
    "def hdc_train(hdc_data, device, hdc_args):\n",
    "    hdc_data_loader = torch.utils.data.DataLoader(hdc_data, batch_size=len(hdc_data), shuffle=True)\n",
    "    hdc_model = hdc.HDC(hdc_args[\"one_d_len\"], hdc_args[\"hdc_proj_len\"], len(hdc_args[\"labels\"]), device)\n",
    "    train_acc = hdc_model.train(hdc_data_loader, device)\n",
    "    return hdc_model\n",
    "\n",
    "if hdc_dp_attack[\"is\"]:\n",
    "    hdc_tasks = [hdc_train(clients_data[clients[client]], device,\n",
    "                            hdc_dp_attack[\"args\"]) for client in mal_clients]\n",
    "    try:\n",
    "        hdc_models = fedargs.loop.run_until_complete(asyncio.gather(*hdc_tasks))\n",
    "    except KeyboardInterrupt as e:\n",
    "        log.error(\"Caught keyboard interrupt. Canceling hdc_dps...\")\n",
    "        hdc_tasks.cancel()\n",
    "        fedargs.loop.run_forever()\n",
    "        hdc_tasks.exception()\n",
    "\n",
    "    hdc_clients_data = {client: (clients_data[clients[client]], hdc_models[index])\n",
    "                        for index, client in enumerate(mal_clients)}\n",
    "\n",
    "    mal_clients_data = hdc_dp_attack[\"func\"](hdc_clients_data,\n",
    "                                             hdc_dp_attack[\"args\"],\n",
    "                                             label_flip_attack[\"labels\"],\n",
    "                                             hdc_dp_attack[\"percent\"])\n",
    "\n",
    "    for client, mal_data in enumerate(mal_clients_data):\n",
    "        clients_data[clients[client]] = mal_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0670c19d",
   "metadata": {},
   "source": [
    "<h2>Label Flip Attack</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43985c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if label_flip_attack[\"is\"]:\n",
    "    for client in mal_clients:\n",
    "        clients_data[clients[client]] = label_flip_attack[\"func\"](clients_data[clients[client]],\n",
    "                                                                  label_flip_attack[\"labels\"],\n",
    "                                                                  label_flip_attack[\"percent\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c01394f",
   "metadata": {},
   "source": [
    "<h2>Backdoor Attack</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11198f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "if backdoor_attack[\"is\"]:\n",
    "    for client in mal_clients:\n",
    "        clients_data[clients[client]] = poison.insert_trojan(clients_data[clients[client]],\n",
    "                                                             backdoor_attack[\"target_label\"],\n",
    "                                                             backdoor_attack[\"trojan_func\"], 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f21c1481",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_train_loaders, _ = data.load_client_data(clients_data, fedargs.client_batch_size, None, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=fedargs.test_batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "client_details = {\n",
    "        client: {\"train_loader\": client_train_loaders[client],\n",
    "                 \"model\": copy.deepcopy(global_model),\n",
    "                 \"model_update\": None}\n",
    "        for client in clients\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af4f472f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def background(f):\n",
    "    def wrapped(*args, **kwargs):\n",
    "        return asyncio.get_event_loop().run_in_executor(None, f, *args, **kwargs)\n",
    "\n",
    "    return wrapped\n",
    "\n",
    "@background\n",
    "def process(client, epoch, model, train_loader, fedargs, device):\n",
    "    # Train\n",
    "    model_update, model, loss = fedargs.train_func(model, train_loader, \n",
    "                                                   fedargs.learning_rate,\n",
    "                                                   fedargs.weight_decay,\n",
    "                                                   fedargs.local_rounds, device)\n",
    "\n",
    "    log.jsondebug(loss, \"Epoch {} of {} : Federated Training loss, Client {}\".format(epoch, fedargs.epochs, client))\n",
    "    log.modeldebug(model_update, \"Epoch {} of {} : Client {} Update\".format(epoch, fedargs.epochs, client))\n",
    "    \n",
    "    return model_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3f7f3fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/21 [00:00<?, ?it/s]2023-10-15 18:58:55,643 - /var/folders/bt/rxysq_fs7ggf93mf5dc5250r0000gr/T/ipykernel_40774/2580268256.py::<module>(l:6) : Federated Training Epoch 0 of 21 [MainProcess : MainThread (INFO)]\n",
      "/Users/hkasyap/anaconda3/envs/rev/lib/python3.10/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*before 0.2906899\n",
      "*after1 0.7459789\n",
      "*after2 -0.21535966\n",
      "*before 0.2974705\n",
      "*after1 0.75534254\n",
      "*after2 -0.2244314\n",
      "*before 0.29644433\n",
      "*after1 0.7546027\n",
      "*after2 -0.21646799\n",
      "*before 0.29825947\n",
      "*after1 0.75787264\n",
      "*after2 -0.21060508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|██                                          | 1/21 [00:59<19:45, 59.25s/it]2023-10-15 18:59:54,633 - /var/folders/bt/rxysq_fs7ggf93mf5dc5250r0000gr/T/ipykernel_40774/2580268256.py::<module>(l:6) : Federated Training Epoch 1 of 21 [MainProcess : MainThread (INFO)]\n",
      "2023-10-15 18:59:54,901 - /Users/hkasyap/Desktop/ATI/fl/libs/agg.py::FLTrust(l:269) : Cosine Score [0.17280233, 0.16343425, 0.16883293, 0.17035615, 0.28356072, 0.2747339, 0.3072441, 0.30303285, 0.28361374, 0.2807615] [MainProcess : MainThread (INFO)]\n",
      "2023-10-15 18:59:54,909 - /Users/hkasyap/Desktop/ATI/fl/libs/agg.py::FLTrust(l:270) : FLTrust Score [0.0025945648, 0.0023759822, 0.0025890868, 0.0025825265, 0.018679593, 0.017895324, 0.020620974, 0.020740492, 0.019069578, 0.01845777] [MainProcess : MainThread (INFO)]\n",
      "2023-10-15 18:59:56,964 - /var/folders/bt/rxysq_fs7ggf93mf5dc5250r0000gr/T/ipykernel_40774/2580268256.py::<module>(l:23) : Global Test Outut after Epoch 1 of 21 {\n",
      "    \"accuracy\": 28.199999999999996,\n",
      "    \"correct\": 2820,\n",
      "    \"test_loss\": -0.10923324562311172\n",
      "} [MainProcess : MainThread (INFO)]\n",
      "  5%|██                                         | 1/21 [01:49<36:31, 109.59s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 95\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# For cosine attack, Malicious Clients\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cosine_attack[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m---> 95\u001b[0m     p_models, params_changed \u001b[38;5;241m=\u001b[39m \u001b[43mcosine_attack\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_model_update\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcosine_attack\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43margs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mclient_model_updates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmal_clients\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcosine_attack\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m client, p_model \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(p_models):\n\u001b[1;32m     99\u001b[0m         client_details[clients[client]][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_update\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m p_model \n",
      "File \u001b[0;32m~/Desktop/ATI/fl/libs/poison.py:403\u001b[0m, in \u001b[0;36msine_attack\u001b[0;34m(base_model_update, cosine_args, epoch, models, n_attackers, kn)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Pool(n_attackers) \u001b[38;5;28;01mas\u001b[39;00m p:\n\u001b[1;32m    402\u001b[0m     func \u001b[38;5;241m=\u001b[39m partial(model_poison_cosine_coord, b_arr, cosine_args)\n\u001b[0;32m--> 403\u001b[0m     p_models \u001b[38;5;241m=\u001b[39m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43msim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_net_arr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mattacker\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mattacker\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_attackers\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    404\u001b[0m     p\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m    405\u001b[0m     p\u001b[38;5;241m.\u001b[39mjoin()\n",
      "File \u001b[0;32m~/anaconda3/envs/rev/lib/python3.10/multiprocessing/pool.py:367\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    363\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;124;03m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rev/lib/python3.10/multiprocessing/pool.py:768\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    770\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/rev/lib/python3.10/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rev/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/anaconda3/envs/rev/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "    \n",
    "# Federated Training\n",
    "for epoch in tqdm(range(fedargs.epochs)):\n",
    "    log.info(\"Federated Training Epoch {} of {}\".format(epoch, fedargs.epochs))\n",
    "\n",
    "    # Global Model Update\n",
    "    if epoch > 0:\n",
    "        # For Tmean and FLTrust, not impacts others as of now\n",
    "        avgargs = {\"beta\": len(mal_clients), \n",
    "                   \"base_model_update\": global_model_update if FLTrust[\"is\"] else None,\n",
    "                   \"base_norm\": True,\n",
    "                   \"val_data_loader\": FLTrust[\"loader\"]}\n",
    "        \n",
    "        # Average\n",
    "        global_model = fl.federated_avg(client_model_updates, global_model, fedargs.agg_rule, **avgargs)\n",
    "        log.modeldebug(global_model, \"Epoch {}: Server Update\".format(epoch))\n",
    "        \n",
    "        # Test, Plot and Log\n",
    "        global_test_output = fedargs.eval_func(global_model, test_loader, device, label_flip_attack[\"labels\"])\n",
    "        wb.log({\"epoch\": epoch, \"time\": time.time(), \"acc\": global_test_output[\"accuracy\"], \"loss\": global_test_output[\"test_loss\"]})\n",
    "        log.jsoninfo(global_test_output, \"Global Test Outut after Epoch {} of {}\".format(epoch, fedargs.epochs))\n",
    "        \n",
    "        # Evaluate LFA\n",
    "        if \"attack\" in global_test_output:\n",
    "            if \"attack_success_rate\" in global_test_output[\"attack\"]:\n",
    "                wb.log({\"attack_success_rate\": global_test_output[\"attack\"][\"attack_success_rate\"]})\n",
    "            if \"misclassification_rate\" in global_test_output[\"attack\"]:\n",
    "                wb.log({\"misclassification_rate\": global_test_output[\"attack\"][\"misclassification_rate\"]})\n",
    "\n",
    "        # Evaluate Backdoor\n",
    "        if backdoor_attack[\"is\"]:\n",
    "            backdoor_test_output = fl.backdoor_test(global_model, backdoor_attack[\"loader\"], device, backdoor_attack[\"target_label\"])\n",
    "            wb.log({\"backdoor_success_rate\": backdoor_test_output[\"accuracy\"]})\n",
    "            log.jsoninfo(backdoor_test_output, \"Backdoor Test Outut after Epoch {} of {}\".format(epoch, fedargs.epochs))\n",
    "\n",
    "        # Update client models\n",
    "        for client in clients:\n",
    "            client_details[client]['model'] = copy.deepcopy(global_model)\n",
    "\n",
    "    # Clients\n",
    "    tasks = [process(client, epoch, client_details[client]['model'],\n",
    "                     client_details[client]['train_loader'],\n",
    "                     fedargs, device) for client in clients]\n",
    "    try:\n",
    "        updates = fedargs.loop.run_until_complete(asyncio.gather(*tasks))\n",
    "    except KeyboardInterrupt as e:\n",
    "        log.error(\"Caught keyboard interrupt. Canceling tasks...\")\n",
    "        tasks.cancel()\n",
    "        fedargs.loop.run_forever()\n",
    "        tasks.exception()\n",
    "\n",
    "    for client, update in zip(clients, updates):\n",
    "        client_details[client]['model_update'] = update\n",
    "    client_model_updates = {client: details[\"model_update\"] for client, details in client_details.items()}\n",
    "    \n",
    "    # Fang attack\n",
    "    if fang_attack[\"is\"]:\n",
    "        client_model_updates = fang_attack[\"func\"](client_model_updates, len(mal_clients), fang_attack[\"kn\"])\n",
    "        \n",
    "    # LIE attack\n",
    "    if lie_attack[\"is\"]:\n",
    "        client_model_updates = lie_attack[\"func\"](client_model_updates, len(mal_clients), lie_attack[\"kn\"])\n",
    "   \n",
    "    # SOTA attack\n",
    "    if sota_attack[\"is\"]:\n",
    "        client_model_updates = sota_attack[\"func\"](client_model_updates, len(mal_clients), \n",
    "                                                   sota_attack[\"kn\"], sota_attack[\"dev_type\"])\n",
    "    \n",
    "    # FLtrust or FLTC based aggregation rules or attacks\n",
    "    if FLTrust[\"is\"]:\n",
    "        global_model_update, _, _ = fedargs.train_func(global_model, FLTrust[\"loader\"],\n",
    "                                                       fedargs.learning_rate,\n",
    "                                                       fedargs.weight_decay,\n",
    "                                                       fedargs.local_rounds, device)\n",
    "\n",
    "        # For Attacks related to FLTrust\n",
    "        base_model_update = global_model_update\n",
    "        if FLTrust[\"proxy\"][\"is\"]:\n",
    "            base_model_update, _, _ = fedargs.train_func(global_model, FLTrust[\"proxy\"][\"loader\"],\n",
    "                                                         fedargs.learning_rate,\n",
    "                                                         fedargs.weight_decay,\n",
    "                                                         fedargs.local_rounds, device)\n",
    "        \n",
    "        # Layer replacement attack\n",
    "        if layer_replacement_attack[\"is\"]:\n",
    "            for client in mal_clients:\n",
    "                client_details[clients[client]]['model_update'] = layer_replacement_attack[\"func\"](base_model_update,\n",
    "                                                                                                   client_details[clients[client]]['model_update'],\n",
    "                                                                                                   layer_replacement_attack[\"layers\"])\n",
    "\n",
    "        # For cosine attack, Malicious Clients\n",
    "        if cosine_attack[\"is\"]:\n",
    "            p_models, params_changed = cosine_attack[\"func\"](base_model_update, cosine_attack[\"args\"], epoch,\n",
    "                                                             client_model_updates, len(mal_clients), cosine_attack[\"kn\"])\n",
    "            \n",
    "            for client, p_model in enumerate(p_models):\n",
    "                client_details[clients[client]]['model_update'] = p_model \n",
    "\n",
    "            #plot params changed for only one client\n",
    "            fedargs.tb.add_scalar(\"Params Changed for Cosine Attack/\", params_changed, epoch)\n",
    "\n",
    "        # For sybil attack, Malicious Clients\n",
    "        if sybil_attack[\"is\"]:\n",
    "            for client in mal_clients:\n",
    "                client_details[clients[client]]['model_update'] = base_model_update\n",
    "                \n",
    "        # again pair, as changed during attack\n",
    "        client_model_updates = {client: details[\"model_update\"] for client, details in client_details.items()}\n",
    "\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b2d6a9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<h1> End </h1>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rev]",
   "language": "python",
   "name": "conda-env-rev-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
