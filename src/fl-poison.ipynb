{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a189859",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hkasyap/anaconda3/envs/tenseal/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import asyncio, nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import copy, os, socket, sys, time\n",
    "from functools import partial\n",
    "from multiprocessing import Pool, Process\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), \"../\")))\n",
    "from libs import agg, data, fl, log, nn, plot, poison, resnet, sim, wandb\n",
    "from cfgs.fedargs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e7e0cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-24 10:21:13,751 - Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving. [MainProcess : MainThread (ERROR)]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkasyah\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/hkasyap/Desktop/ATI/fl/libs/../out/wandb/run-20241124_102115-ittmsefs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kasyah/fl-edgeai/runs/ittmsefs' target=\"_blank\">fedavg-cnn-mnist-na</a></strong> to <a href='https://wandb.ai/kasyah/fl-edgeai' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kasyah/fl-edgeai' target=\"_blank\">https://wandb.ai/kasyah/fl-edgeai</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kasyah/fl-edgeai/runs/ittmsefs' target=\"_blank\">https://wandb.ai/kasyah/fl-edgeai/runs/ittmsefs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "project = 'fl-edgeai'\n",
    "name = 'fedavg-cnn-mnist-na'\n",
    "\n",
    "#Define Custom CFGs\n",
    "torch.manual_seed(1)\n",
    "\n",
    "fedargs.enc = True\n",
    "fedargs.num_clients = 10\n",
    "fedargs.epochs = 11\n",
    "\n",
    "#fedargs.dataset = \"fmnist\"\n",
    "#fedargs.agg_rule = agg.Rule.FLTrust\n",
    "#FLTrust[\"is\"] = True\n",
    "#FLTrust[\"proxy\"][\"is\"] = True\n",
    "\n",
    "#cosine_attack[\"is\"] = True\n",
    "#cosine_attack[\"kn\"] = poison.Knowledge.IN\n",
    "#mal_clients = [c for c in range(4)]\n",
    "\n",
    "# Save Logs To File (info | debug | warning | error | critical) [optional]\n",
    "log.init(\"info\")\n",
    "wb = wandb.init(name, project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bb399c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device settings\n",
    "use_cuda = fedargs.cuda and torch.cuda.is_available()\n",
    "torch.manual_seed(fedargs.seed)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "kwargs = {\"num_workers\": 1, \"pin_memory\": True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76542fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare clients\n",
    "host = socket.gethostname()\n",
    "clients = [host + \"(\" + str(client + 1) + \")\" for client in range(fedargs.num_clients)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "402306c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Global and Client models\n",
    "global_model = copy.deepcopy(fedargs.model)\n",
    "# Load Data to clients\n",
    "train_data, test_data = data.load_dataset(fedargs.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca573ed",
   "metadata": {},
   "source": [
    "<h2>FLTrust</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbe42e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "if FLTrust[\"is\"]:\n",
    "    train_data, FLTrust[\"data\"] = data.random_split(train_data, FLTrust[\"ratio\"])\n",
    "    FLTrust[\"loader\"] = torch.utils.data.DataLoader(FLTrust[\"data\"], batch_size=len(FLTrust[\"data\"]), shuffle=True, **kwargs)\n",
    "    \n",
    "    if FLTrust[\"proxy\"][\"is\"]:\n",
    "        FLTrust[\"data\"], FLTrust[\"proxy\"][\"data\"] = data.random_split(FLTrust[\"data\"], FLTrust[\"proxy\"][\"ratio\"])\n",
    "        FLTrust[\"loader\"] = torch.utils.data.DataLoader(FLTrust[\"data\"], batch_size=fedargs.client_batch_size, shuffle=True, **kwargs)\n",
    "        FLTrust[\"proxy\"][\"loader\"] = torch.utils.data.DataLoader(FLTrust[\"proxy\"][\"data\"], batch_size=fedargs.client_batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8025440b",
   "metadata": {},
   "source": [
    "<h2>Prepare a backdoored loader for test</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "769acb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "if backdoor_attack[\"is\"]:\n",
    "    train_data, backdoor_attack[\"data\"] = data.random_split(train_data, backdoor_attack[\"ratio\"])\n",
    "    backdoor_attack[\"data\"] = poison.insert_trojan(backdoor_attack[\"data\"],\n",
    "                                                   backdoor_attack[\"target_label\"],\n",
    "                                                   backdoor_attack[\"trojan_func\"], 1)\n",
    "    backdoor_attack[\"loader\"] = torch.utils.data.DataLoader(backdoor_attack[\"data\"], batch_size=fedargs.client_batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f568d4",
   "metadata": {},
   "source": [
    "<h2>Load client's data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80508740",
   "metadata": {},
   "outputs": [],
   "source": [
    "clients_data = data.split_data(train_data, clients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87aacd7b",
   "metadata": {},
   "source": [
    "<h2>HDC DP Attack</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c15880d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def background(f):\n",
    "    def wrapped(*args, **kwargs):\n",
    "        return asyncio.get_event_loop().run_in_executor(None, f, *args, **kwargs)\n",
    "\n",
    "    return wrapped\n",
    "\n",
    "@background\n",
    "def hdc_train(hdc_data, device, hdc_args):\n",
    "    hdc_data_loader = torch.utils.data.DataLoader(hdc_data, batch_size=len(hdc_data), shuffle=True)\n",
    "    hdc_model = hdc.HDC(hdc_args[\"one_d_len\"], hdc_args[\"hdc_proj_len\"], len(hdc_args[\"labels\"]), device)\n",
    "    train_acc = hdc_model.train(hdc_data_loader, device)\n",
    "    return hdc_model\n",
    "\n",
    "if hdc_dp_attack[\"is\"]:\n",
    "    hdc_tasks = [hdc_train(clients_data[clients[client]], device,\n",
    "                            hdc_dp_attack[\"args\"]) for client in mal_clients]\n",
    "    try:\n",
    "        hdc_models = fedargs.loop.run_until_complete(asyncio.gather(*hdc_tasks))\n",
    "    except KeyboardInterrupt as e:\n",
    "        log.error(\"Caught keyboard interrupt. Canceling hdc_dps...\")\n",
    "        hdc_tasks.cancel()\n",
    "        fedargs.loop.run_forever()\n",
    "        hdc_tasks.exception()\n",
    "\n",
    "    hdc_clients_data = {client: (clients_data[clients[client]], hdc_models[index])\n",
    "                        for index, client in enumerate(mal_clients)}\n",
    "\n",
    "    mal_clients_data = hdc_dp_attack[\"func\"](hdc_clients_data,\n",
    "                                             hdc_dp_attack[\"args\"],\n",
    "                                             label_flip_attack[\"labels\"],\n",
    "                                             hdc_dp_attack[\"percent\"])\n",
    "\n",
    "    for client, mal_data in enumerate(mal_clients_data):\n",
    "        clients_data[clients[client]] = mal_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0670c19d",
   "metadata": {},
   "source": [
    "<h2>Label Flip Attack</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43985c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if label_flip_attack[\"is\"]:\n",
    "    for client in mal_clients:\n",
    "        clients_data[clients[client]] = label_flip_attack[\"func\"](clients_data[clients[client]],\n",
    "                                                                  label_flip_attack[\"labels\"],\n",
    "                                                                  label_flip_attack[\"percent\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c01394f",
   "metadata": {},
   "source": [
    "<h2>Backdoor Attack</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11198f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "if backdoor_attack[\"is\"]:\n",
    "    for client in mal_clients:\n",
    "        clients_data[clients[client]] = poison.insert_trojan(clients_data[clients[client]],\n",
    "                                                             backdoor_attack[\"target_label\"],\n",
    "                                                             backdoor_attack[\"trojan_func\"], 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f21c1481",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_train_loaders, _ = data.load_client_data(clients_data, fedargs.client_batch_size, None, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=fedargs.test_batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "client_details = {\n",
    "        client: {\"train_loader\": client_train_loaders[client],\n",
    "                 \"model\": copy.deepcopy(global_model),\n",
    "                 \"model_update\": None}\n",
    "        for client in clients\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af4f472f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def background(f):\n",
    "    def wrapped(*args, **kwargs):\n",
    "        return asyncio.get_event_loop().run_in_executor(None, f, *args, **kwargs)\n",
    "\n",
    "    return wrapped\n",
    "\n",
    "@background\n",
    "def process(client, epoch, model, train_loader, fedargs, device):\n",
    "    # Train\n",
    "    model_update, model, loss = fedargs.train_func(model, train_loader, \n",
    "                                                   fedargs.learning_rate,\n",
    "                                                   fedargs.weight_decay,\n",
    "                                                   fedargs.local_rounds, device)\n",
    "\n",
    "    log.jsondebug(loss, \"Epoch {} of {} : Federated Training loss, Client {}\".format(epoch, fedargs.epochs, client))\n",
    "    log.modeldebug(model_update, \"Epoch {} of {} : Client {} Update\".format(epoch, fedargs.epochs, client))\n",
    "    \n",
    "    return model_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f7f3fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                               | 0/11 [00:00<?, ?it/s]2024-11-24 10:21:24,902 - /var/folders/bt/rxysq_fs7ggf93mf5dc5250r0000gr/T/ipykernel_97931/2580268256.py::<module>(l:6) : Federated Training Epoch 0 of 11 [MainProcess : MainThread (INFO)]\n",
      "/Users/hkasyap/anaconda3/envs/tenseal/lib/python3.10/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "    \n",
    "# Federated Training\n",
    "for epoch in tqdm(range(fedargs.epochs)):\n",
    "    log.info(\"Federated Training Epoch {} of {}\".format(epoch, fedargs.epochs))\n",
    "\n",
    "    # Global Model Update\n",
    "    if epoch > 0:\n",
    "        # For Tmean and FLTrust, not impacts others as of now\n",
    "        avgargs = {\"beta\": len(mal_clients), \n",
    "                   \"base_model_update\": global_model_update if FLTrust[\"is\"] else None,\n",
    "                   \"base_norm\": True,\n",
    "                   \"val_data_loader\": FLTrust[\"loader\"]}\n",
    "        \n",
    "        # Average\n",
    "        global_model = fl.federated_avg(client_model_updates, global_model, fedargs.agg_rule, **avgargs)\n",
    "        log.modeldebug(global_model, \"Epoch {}: Server Update\".format(epoch))\n",
    "        \n",
    "        # Test, Plot and Log\n",
    "        global_test_output = fedargs.eval_func(global_model, test_loader, device, label_flip_attack[\"labels\"])\n",
    "        wb.log({\"epoch\": epoch, \"time\": time.time(), \"acc\": global_test_output[\"accuracy\"], \"loss\": global_test_output[\"test_loss\"]})\n",
    "        log.jsoninfo(global_test_output, \"Global Test Outut after Epoch {} of {}\".format(epoch, fedargs.epochs))\n",
    "        \n",
    "        # Evaluate LFA\n",
    "        if \"attack\" in global_test_output:\n",
    "            if \"attack_success_rate\" in global_test_output[\"attack\"]:\n",
    "                wb.log({\"attack_success_rate\": global_test_output[\"attack\"][\"attack_success_rate\"]})\n",
    "            if \"misclassification_rate\" in global_test_output[\"attack\"]:\n",
    "                wb.log({\"misclassification_rate\": global_test_output[\"attack\"][\"misclassification_rate\"]})\n",
    "\n",
    "        # Evaluate Backdoor\n",
    "        if backdoor_attack[\"is\"]:\n",
    "            backdoor_test_output = fl.backdoor_test(global_model, backdoor_attack[\"loader\"], device, backdoor_attack[\"target_label\"])\n",
    "            wb.log({\"backdoor_success_rate\": backdoor_test_output[\"accuracy\"]})\n",
    "            log.jsoninfo(backdoor_test_output, \"Backdoor Test Outut after Epoch {} of {}\".format(epoch, fedargs.epochs))\n",
    "\n",
    "        # Update client models\n",
    "        for client in clients:\n",
    "            client_details[client]['model'] = copy.deepcopy(global_model)\n",
    "\n",
    "    # Clients\n",
    "    tasks = [process(client, epoch, client_details[client]['model'],\n",
    "                     client_details[client]['train_loader'],\n",
    "                     fedargs, device) for client in clients]\n",
    "    try:\n",
    "        updates = fedargs.loop.run_until_complete(asyncio.gather(*tasks))\n",
    "    except KeyboardInterrupt as e:\n",
    "        log.error(\"Caught keyboard interrupt. Canceling tasks...\")\n",
    "        tasks.cancel()\n",
    "        fedargs.loop.run_forever()\n",
    "        tasks.exception()\n",
    "\n",
    "    for client, update in zip(clients, updates):\n",
    "        client_details[client]['model_update'] = update\n",
    "    client_model_updates = {client: details[\"model_update\"] for client, details in client_details.items()}\n",
    "    \n",
    "    # Fang attack\n",
    "    if fang_attack[\"is\"]:\n",
    "        client_model_updates = fang_attack[\"func\"](client_model_updates, len(mal_clients), fang_attack[\"kn\"])\n",
    "        \n",
    "    # LIE attack\n",
    "    if lie_attack[\"is\"]:\n",
    "        client_model_updates = lie_attack[\"func\"](client_model_updates, len(mal_clients), lie_attack[\"kn\"])\n",
    "   \n",
    "    # SOTA attack\n",
    "    if sota_attack[\"is\"]:\n",
    "        client_model_updates = sota_attack[\"func\"](client_model_updates, len(mal_clients), \n",
    "                                                   sota_attack[\"kn\"], sota_attack[\"dev_type\"])\n",
    "    \n",
    "    # FLtrust or FLTC based aggregation rules or attacks\n",
    "    if FLTrust[\"is\"]:\n",
    "        global_model_update, _, _ = fedargs.train_func(global_model, FLTrust[\"loader\"],\n",
    "                                                       fedargs.learning_rate,\n",
    "                                                       fedargs.weight_decay,\n",
    "                                                       fedargs.local_rounds, device)\n",
    "\n",
    "        # For Attacks related to FLTrust\n",
    "        base_model_update = global_model_update\n",
    "        if FLTrust[\"proxy\"][\"is\"]:\n",
    "            base_model_update, _, _ = fedargs.train_func(global_model, FLTrust[\"proxy\"][\"loader\"],\n",
    "                                                         fedargs.learning_rate,\n",
    "                                                         fedargs.weight_decay,\n",
    "                                                         fedargs.local_rounds, device)\n",
    "        \n",
    "        # Layer replacement attack\n",
    "        if layer_replacement_attack[\"is\"]:\n",
    "            for client in mal_clients:\n",
    "                client_details[clients[client]]['model_update'] = layer_replacement_attack[\"func\"](base_model_update,\n",
    "                                                                                                   client_details[clients[client]]['model_update'],\n",
    "                                                                                                   layer_replacement_attack[\"layers\"])\n",
    "\n",
    "        # For cosine attack, Malicious Clients\n",
    "        if cosine_attack[\"is\"]:\n",
    "            p_models, params_changed = cosine_attack[\"func\"](base_model_update, cosine_attack[\"args\"], epoch,\n",
    "                                                             client_model_updates, len(mal_clients), cosine_attack[\"kn\"])\n",
    "            \n",
    "            for client, p_model in enumerate(p_models):\n",
    "                client_details[clients[client]]['model_update'] = p_model \n",
    "\n",
    "            #plot params changed for only one client\n",
    "            fedargs.tb.add_scalar(\"Params Changed for Cosine Attack/\", params_changed, epoch)\n",
    "\n",
    "        # For sybil attack, Malicious Clients\n",
    "        if sybil_attack[\"is\"]:\n",
    "            for client in mal_clients:\n",
    "                client_details[clients[client]]['model_update'] = base_model_update\n",
    "                \n",
    "        # again pair, as changed during attack\n",
    "        client_model_updates = {client: details[\"model_update\"] for client, details in client_details.items()}\n",
    "\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b2d6a9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<h1> End </h1>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tenseal]",
   "language": "python",
   "name": "conda-env-tenseal-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
