{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30d6b8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import os, sys\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), \"../../\")))\n",
    "from libs import data as dt, neuronshap as ns, sim\n",
    "from cfgs.fedargs import *\n",
    "\n",
    "from fairlearn.metrics import (\n",
    "    demographic_parity_difference,\n",
    "    demographic_parity_ratio,\n",
    "    equalized_odds_difference,\n",
    "    equalized_odds_ratio,\n",
    ")\n",
    "from libs.helpers.finance import bin_hours_per_week, bin_NATIVITY_level, test_RACIP_enum\n",
    "from libs.helpers.metrics import (\n",
    "    conditional_demographic_parity_difference,\n",
    "    conditional_demographic_parity_ratio,\n",
    ")\n",
    "from libs.helpers.plot import group_box_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03742d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hkasyap/anaconda3/envs/shap/lib/python3.10/site-packages/sklearn/utils/validation.py:753: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/hkasyap/anaconda3/envs/shap/lib/python3.10/site-packages/sklearn/utils/validation.py:591: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/hkasyap/anaconda3/envs/shap/lib/python3.10/site-packages/sklearn/utils/validation.py:600: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/hkasyap/anaconda3/envs/shap/lib/python3.10/site-packages/sklearn/utils/validation.py:753: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/hkasyap/anaconda3/envs/shap/lib/python3.10/site-packages/sklearn/utils/validation.py:591: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/hkasyap/anaconda3/envs/shap/lib/python3.10/site-packages/sklearn/utils/validation.py:600: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/var/folders/bt/rxysq_fs7ggf93mf5dc5250r0000gr/T/ipykernel_64616/35387852.py:19: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  df[df['SEX'] == 2.0] = 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGEP</th>\n",
       "      <th>NATIVITY</th>\n",
       "      <th>SEX</th>\n",
       "      <th>RAC1P</th>\n",
       "      <th>ESR</th>\n",
       "      <th>SCHL_0.0</th>\n",
       "      <th>SCHL_1.0</th>\n",
       "      <th>SCHL_2.0</th>\n",
       "      <th>SCHL_3.0</th>\n",
       "      <th>SCHL_4.0</th>\n",
       "      <th>...</th>\n",
       "      <th>ANC_2.0</th>\n",
       "      <th>ANC_3.0</th>\n",
       "      <th>ANC_4.0</th>\n",
       "      <th>DEAR_1.0</th>\n",
       "      <th>DEAR_2.0</th>\n",
       "      <th>DEYE_1.0</th>\n",
       "      <th>DEYE_2.0</th>\n",
       "      <th>DREM_0.0</th>\n",
       "      <th>DREM_1.0</th>\n",
       "      <th>DREM_2.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.429499</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.620885</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.200731</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.074685</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       AGEP  NATIVITY  SEX  RAC1P  ESR SCHL_0.0 SCHL_1.0 SCHL_2.0 SCHL_3.0  \\\n",
       "0  0.000000         0    0    0.0    0        0        0        0        0   \n",
       "1  0.000000         0    0    0.0    0        0        0        0        0   \n",
       "2  0.429499         1    1    1.0    0    False    False    False    False   \n",
       "3 -0.620885         1    1    1.0    0    False    False    False    False   \n",
       "4  0.000000         0    0    0.0    0        0        0        0        0   \n",
       "5  0.000000         0    0    0.0    0        0        0        0        0   \n",
       "6  0.000000         0    0    0.0    0        0        0        0        0   \n",
       "7 -0.200731         1    1    1.0    0    False    False    False    False   \n",
       "8 -0.074685         1    1    1.0    1    False    False    False    False   \n",
       "9  0.000000         0    0    0.0    0        0        0        0        0   \n",
       "\n",
       "  SCHL_4.0  ... ANC_2.0 ANC_3.0 ANC_4.0 DEAR_1.0 DEAR_2.0 DEYE_1.0 DEYE_2.0  \\\n",
       "0        0  ...       0       0       0        0        0        0        0   \n",
       "1        0  ...       0       0       0        0        0        0        0   \n",
       "2    False  ...    True   False   False    False     True    False     True   \n",
       "3    False  ...   False   False   False    False     True    False     True   \n",
       "4        0  ...       0       0       0        0        0        0        0   \n",
       "5        0  ...       0       0       0        0        0        0        0   \n",
       "6        0  ...       0       0       0        0        0        0        0   \n",
       "7    False  ...   False   False    True     True    False    False     True   \n",
       "8    False  ...   False   False    True    False     True    False     True   \n",
       "9        0  ...       0       0       0        0        0        0        0   \n",
       "\n",
       "  DREM_0.0 DREM_1.0 DREM_2.0  \n",
       "0        0        0        0  \n",
       "1        0        0        0  \n",
       "2    False     True    False  \n",
       "3    False    False     True  \n",
       "4        0        0        0  \n",
       "5        0        0        0  \n",
       "6        0        0        0  \n",
       "7    False    False     True  \n",
       "8    False    False     True  \n",
       "9        0        0        0  \n",
       "\n",
       "[10 rows x 89 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from folktables import ACSDataSource, ACSEmployment\n",
    "\n",
    "data_source = ACSDataSource(survey_year='2018', horizon='1-Year', survey='person')\n",
    "acs_data = data_source.get_data(states=[\"AL\"], download=True)\n",
    "features, label, group = ACSEmployment.df_to_numpy(acs_data)\n",
    "\n",
    "df = pd.DataFrame(features)\n",
    "df.columns = ACSEmployment.features\n",
    "df[ACSEmployment.target] = label\n",
    "\n",
    "categorical_features = ['SCHL','MAR', 'RELP', 'DIS', 'ESP', 'CIT', 'MIG', 'MIL', 'ANC', 'DEAR', 'DEYE', 'DREM']\n",
    "df = pd.get_dummies(df, columns = categorical_features)\n",
    "\n",
    "numeric_features = ['AGEP']\n",
    "ss = StandardScaler()\n",
    "df[numeric_features] = ss.fit_transform(df[numeric_features])\n",
    "\n",
    "#df[df['SEX'] == 1.0] = 1\n",
    "df[df['SEX'] == 2.0] = 0\n",
    "#df[df['RAC1P'] != 1.0] = 0\n",
    "df['ESR'] = df['ESR'].astype('int')\n",
    "df['SEX'] = df['SEX'].astype('int')\n",
    "#df['RAC1P'] = df['RAC1P'].astype('int')\n",
    "df['NATIVITY'] = df['NATIVITY'].astype('int')\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e364942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGEP</th>\n",
       "      <th>NATIVITY</th>\n",
       "      <th>SEX</th>\n",
       "      <th>RAC1P</th>\n",
       "      <th>ESR</th>\n",
       "      <th>SCHL_0.0</th>\n",
       "      <th>SCHL_1.0</th>\n",
       "      <th>SCHL_2.0</th>\n",
       "      <th>SCHL_3.0</th>\n",
       "      <th>SCHL_4.0</th>\n",
       "      <th>...</th>\n",
       "      <th>ANC_2.0</th>\n",
       "      <th>ANC_3.0</th>\n",
       "      <th>ANC_4.0</th>\n",
       "      <th>DEAR_1.0</th>\n",
       "      <th>DEAR_2.0</th>\n",
       "      <th>DEYE_1.0</th>\n",
       "      <th>DEYE_2.0</th>\n",
       "      <th>DREM_0.0</th>\n",
       "      <th>DREM_1.0</th>\n",
       "      <th>DREM_2.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25249</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26314</th>\n",
       "      <td>-0.914992</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22376</th>\n",
       "      <td>0.933683</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22654</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14182</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           AGEP  NATIVITY  SEX  RAC1P  ESR SCHL_0.0 SCHL_1.0 SCHL_2.0  \\\n",
       "25249  0.000000         0    0    0.0    0        0        0        0   \n",
       "26314 -0.914992         1    1    1.0    0    False    False    False   \n",
       "22376  0.933683         1    1    1.0    0    False    False    False   \n",
       "22654  0.000000         0    0    0.0    0        0        0        0   \n",
       "14182  0.000000         0    0    0.0    0        0        0        0   \n",
       "\n",
       "      SCHL_3.0 SCHL_4.0  ... ANC_2.0 ANC_3.0 ANC_4.0 DEAR_1.0 DEAR_2.0  \\\n",
       "25249        0        0  ...       0       0       0        0        0   \n",
       "26314    False    False  ...   False   False   False    False     True   \n",
       "22376    False    False  ...   False   False   False    False     True   \n",
       "22654        0        0  ...       0       0       0        0        0   \n",
       "14182        0        0  ...       0       0       0        0        0   \n",
       "\n",
       "      DEYE_1.0 DEYE_2.0 DREM_0.0 DREM_1.0 DREM_2.0  \n",
       "25249        0        0        0        0        0  \n",
       "26314    False     True    False    False     True  \n",
       "22376    False     True    False    False     True  \n",
       "22654        0        0        0        0        0  \n",
       "14182        0        0        0        0        0  \n",
       "\n",
       "[5 rows x 89 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "#https://nannyml.readthedocs.io/en/v0.9.0/datasets/ma_employment.html\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "train_oh, test_oh = copy.deepcopy(train), copy.deepcopy(test)\n",
    "\n",
    "test = test.reset_index(drop=True)\n",
    "test_oh = test_oh.reset_index(drop=True)\n",
    "\n",
    "#categorical_features = ['RAC1P']\n",
    "#train_oh = pd.get_dummies(train_oh, columns = categorical_features)\n",
    "#test_oh = pd.get_dummies(test_oh, columns = categorical_features)\n",
    "\n",
    "train_oh.head()\n",
    "#test.info()\n",
    "#test_oh[\"NATIVITY\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd2c28b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_dh_oh = test_oh.loc[test_oh[\"SEX\"] == 1]\n",
    "m_dh_oh = m_dh_oh.head(100)\n",
    "fm_dh_oh = test_oh.loc[test_oh[\"SEX\"] == 0]\n",
    "fm_dh_oh = fm_dh_oh.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c535017e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 12\u001b[0m\n\u001b[1;32m      8\u001b[0m Y_fm \u001b[38;5;241m=\u001b[39m fm_dh_oh[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mESR\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#creating torch dataset and loader using original dataset. \u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#to use resampled dataset, replace ex. xtrain with xtrain_over etc.\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m train_data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mTensorDataset(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfloat(), torch\u001b[38;5;241m.\u001b[39mtensor(Y_train)\u001b[38;5;241m.\u001b[39mlong())\n\u001b[1;32m     13\u001b[0m test_data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mTensorDataset(torch\u001b[38;5;241m.\u001b[39mtensor(X_test)\u001b[38;5;241m.\u001b[39mfloat(), torch\u001b[38;5;241m.\u001b[39mtensor(Y_test)\u001b[38;5;241m.\u001b[39mlong())\n\u001b[1;32m     14\u001b[0m m_data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mTensorDataset(torch\u001b[38;5;241m.\u001b[39mtensor(X_m)\u001b[38;5;241m.\u001b[39mfloat(), torch\u001b[38;5;241m.\u001b[39mtensor(Y_m)\u001b[38;5;241m.\u001b[39mlong())\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."
     ]
    }
   ],
   "source": [
    "X_train = train_oh.drop(columns=\"ESR\").values\n",
    "Y_train = train_oh['ESR'].values\n",
    "X_test = test_oh.drop(columns=\"ESR\").values\n",
    "Y_test = test_oh['ESR'].values\n",
    "X_m = m_dh_oh.drop(columns=\"ESR\").values\n",
    "Y_m = m_dh_oh['ESR'].values\n",
    "X_fm = fm_dh_oh.drop(columns=\"ESR\").values\n",
    "Y_fm = fm_dh_oh['ESR'].values\n",
    "\n",
    "#creating torch dataset and loader using original dataset. \n",
    "#to use resampled dataset, replace ex. xtrain with xtrain_over etc.\n",
    "train_data = torch.utils.data.TensorDataset(torch.tensor(X_train).float(), torch.tensor(Y_train).long())\n",
    "test_data = torch.utils.data.TensorDataset(torch.tensor(X_test).float(), torch.tensor(Y_test).long())\n",
    "m_data = torch.utils.data.TensorDataset(torch.tensor(X_m).float(), torch.tensor(Y_m).long())\n",
    "fm_data = torch.utils.data.TensorDataset(torch.tensor(X_fm).float(), torch.tensor(Y_fm).long())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data,batch_size=128, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=len(test_data))\n",
    "m_loader = torch.utils.data.DataLoader(m_data, batch_size=1)\n",
    "fm_loader = torch.utils.data.DataLoader(fm_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e242062",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicNet(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super().__init__()\n",
    "        self.num_features = num_features\n",
    "        self.num_classes = num_classes\n",
    "        self.layers = 0\n",
    "        \n",
    "        self.lin1 = torch.nn.Linear(self.num_features,  150)        \n",
    "        self.lin2 = torch.nn.Linear(50, 50)        \n",
    "        self.lin3 = torch.nn.Linear(50, 50)\n",
    "        \n",
    "        self.lin4 = torch.nn.Linear(150, 150) \n",
    "        \n",
    "        self.lin5 = torch.nn.Linear(50, 50)        \n",
    "        self.lin6 = torch.nn.Linear(50, 50)\n",
    "        self.lin10 = torch.nn.Linear(150, self.num_classes)\n",
    "        \n",
    "        self.prelu = torch.nn.PReLU()\n",
    "        self.dropout = torch.nn.Dropout(0.25)\n",
    "\n",
    "    def forward(self, xin):\n",
    "        self.layers = 0\n",
    "        \n",
    "        x = F.relu(self.lin1(xin))\n",
    "        self.layers += 1\n",
    "        \n",
    "        #x = F.relu(self.lin2(x))\n",
    "        #self.layers += 1\n",
    "        for y in range(8):\n",
    "            x = F.relu(self.lin4(x)) \n",
    "            self.layers += 1\n",
    "           \n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = F.relu(self.lin10(x)) \n",
    "        self.layers += 1\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f7df169",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    \n",
    "    for inputs, target in train_loader:\n",
    "      \n",
    "        #inputs, target = inputs.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(inputs)\n",
    "        loss = loss_fn(output, target.long())\n",
    "        # Backprop\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eac1d0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    \n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    test_size = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "      \n",
    "        for inputs, target in test_loader:\n",
    "            \n",
    "            #inputs, target = inputs.to(device), target.to(device)\n",
    "            \n",
    "            output = model(inputs)\n",
    "            test_size += len(inputs)\n",
    "            test_loss += test_loss_fn(output, target.long()).item() \n",
    "            pred = output.max(1, keepdim=True)[1] \n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= test_size\n",
    "    accuracy = correct / test_size\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, test_size,\n",
    "        100. * accuracy))\n",
    "    \n",
    "    return test_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3540472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training beginning...\n",
      "Epoch  1 :\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, nbr_epochs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;124m'\u001b[39m, epoch, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m     train(model, \u001b[43mtrain_loader\u001b[49m, optimizer, epoch)\n\u001b[1;32m     22\u001b[0m     loss, acc \u001b[38;5;241m=\u001b[39m test(model, test_loader)\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m# save results every epoch\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "model = BasicNet(88, 2)\n",
    "test_accuracy = []\n",
    "train_loss = []\n",
    "nbr_epochs = 5\n",
    "lr = 0.0025# \n",
    "weight_decay = 0\n",
    "\n",
    "# Surrogate loss used for training\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "test_loss_fn = torch.nn.CrossEntropyLoss(reduction='sum')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr,weight_decay=weight_decay)\n",
    "#optimizer = optim.SGD(model.parameters(), lr=lr ,weight_decay=weight_decay)\n",
    "#optimizer = optim.RMSprop(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "print('Training beginning...')\n",
    "#start_time = time.time()\n",
    "\n",
    "for epoch in range(1, nbr_epochs+1):\n",
    "    print('Epoch ', epoch, ':')\n",
    "    train(model, train_loader, optimizer, epoch)\n",
    "    loss, acc = test(model, test_loader)\n",
    "    \n",
    "    # save results every epoch\n",
    "    test_accuracy.append(acc)\n",
    "    train_loss.append(loss)\n",
    "    \n",
    "#end_time = time.time()\n",
    "#print('Training on ' + str(nbr_epochs) + ' epochs done in ', str(end_time-start_time),' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cca14a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 8827/9556 (92%)\n",
      "\n",
      "2032 tensor([2053]) tensor([2053])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for inputs, target in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        pred = outputs.max(1, keepdim=True)[1] \n",
    "        correct = pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        accuracy = correct / len(inputs)\n",
    "        print('\\nAccuracy: {}/{} ({:.0f}%)\\n'.format(correct, len(inputs), 100. * accuracy))\n",
    "\n",
    "Y_prob = F.softmax(outputs, dim=1)[:, 1]\n",
    "Y_pred = outputs.max(1, keepdim=True)[1]\n",
    "\n",
    "print(sum(Y_test), sum(Y_pred), sum(pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f221b5",
   "metadata": {},
   "source": [
    "<h1>Demographic Parity</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de150a4",
   "metadata": {},
   "source": [
    "<h2>Distribution of scores by sex</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eae1acc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demographic parity difference: 0.176\n",
      "Demographic parity ratio: 0.000\n"
     ]
    }
   ],
   "source": [
    "dpd = demographic_parity_difference(\n",
    "    Y_test, Y_pred, sensitive_features=test_oh.SEX,\n",
    ")\n",
    "\n",
    "dpr = demographic_parity_ratio(\n",
    "    Y_test, Y_pred, sensitive_features=test_oh.SEX,\n",
    ")\n",
    "\n",
    "print(f\"Demographic parity difference: {dpd:.3f}\")\n",
    "print(f\"Demographic parity ratio: {dpr:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eff63390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demographic parity difference: 0.221\n",
      "Demographic parity ratio: 0.000\n"
     ]
    }
   ],
   "source": [
    "dpd = demographic_parity_difference(\n",
    "    Y_test, Y_pred, sensitive_features=test_oh.NATIVITY,\n",
    ")\n",
    "\n",
    "dpr = demographic_parity_ratio(\n",
    "    Y_test, Y_pred, sensitive_features=test_oh.NATIVITY,\n",
    ")\n",
    "\n",
    "print(f\"Demographic parity difference: {dpd:.3f}\")\n",
    "print(f\"Demographic parity ratio: {dpr:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6d3ab2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conditional demographic parity difference: 0.110\n",
      "Conditional demographic parity ratio: 0.500\n"
     ]
    }
   ],
   "source": [
    "test_RAC1P_enum = test_oh.RAC1P.map(test_RACIP_enum)\n",
    "\n",
    "cdpd = conditional_demographic_parity_difference(\n",
    "    Y_test, Y_pred, test_oh.SEX, test_RAC1P_enum,\n",
    ")\n",
    "cdpr = conditional_demographic_parity_ratio(\n",
    "    Y_test, Y_pred, test_oh.SEX, test_RAC1P_enum,\n",
    ")\n",
    "\n",
    "print(f\"Conditional demographic parity difference: {cdpd:.3f}\")\n",
    "print(f\"Conditional demographic parity ratio: {cdpr:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a03319ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conditional demographic parity difference: 0.219\n",
      "Conditional demographic parity ratio: 0.228\n"
     ]
    }
   ],
   "source": [
    "test_RAC1P_enum = test_oh.RAC1P.map(test_RACIP_enum)\n",
    "\n",
    "cdpd = conditional_demographic_parity_difference(\n",
    "    Y_test, Y_pred, test_oh.NATIVITY, test_RAC1P_enum,\n",
    ")\n",
    "cdpr = conditional_demographic_parity_ratio(\n",
    "    Y_test, Y_pred, test_oh.NATIVITY, test_RAC1P_enum,\n",
    ")\n",
    "\n",
    "print(f\"Conditional demographic parity difference: {cdpd:.3f}\")\n",
    "print(f\"Conditional demographic parity ratio: {cdpr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540eb7be",
   "metadata": {},
   "source": [
    "<h1>Equalised Odds</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83403a17",
   "metadata": {},
   "source": [
    "<h2>Distribution of scores by sex for high and low earners</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ccb4a352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equalised odds difference: 0.360\n",
      "Equalised odds ratio: 0.000\n"
     ]
    }
   ],
   "source": [
    "eod = equalized_odds_difference(\n",
    "    Y_test, Y_pred, sensitive_features=test_oh.SEX,\n",
    ")\n",
    "eor = equalized_odds_ratio(\n",
    "    Y_test, Y_pred, sensitive_features=test_oh.SEX,\n",
    ")\n",
    "\n",
    "print(f\"Equalised odds difference: {eod:.3f}\")\n",
    "print(f\"Equalised odds ratio: {eor:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfe14f3",
   "metadata": {},
   "source": [
    "<h2>Distribution of scores by race for high and low earners</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "282afbe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equalised odds difference: 0.365\n",
      "Equalised odds ratio: 0.000\n"
     ]
    }
   ],
   "source": [
    "eod = equalized_odds_difference(\n",
    "    Y_test, Y_pred, sensitive_features=test_oh.NATIVITY,\n",
    ")\n",
    "eor = equalized_odds_ratio(\n",
    "    Y_test, Y_pred, sensitive_features=test_oh.NATIVITY,\n",
    ")\n",
    "\n",
    "print(f\"Equalised odds difference: {eod:.3f}\")\n",
    "print(f\"Equalised odds ratio: {eor:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a025501d",
   "metadata": {},
   "source": [
    "<h1>Shapley based Neuron Pruning for Fairness</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "907f2736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 136.17596   105.508606    9.646261 ... 1739.7612   1522.7279\n",
      "    0.      ]\n",
      "[  0.       0.       0.     ... 597.6179   0.       0.    ]\n"
     ]
    }
   ],
   "source": [
    "m_shapley_values = ns.calculate_shapley_values_fa(model, m_loader, 200)\n",
    "print(m_shapley_values)\n",
    "fm_shapley_values = ns.calculate_shapley_values_fa(model, fm_loader, 200)\n",
    "print(fm_shapley_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "66e84c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_shap_values = m_shapley_values - fm_shapley_values\n",
    "max_diff_shap_values_ind = np.argpartition(diff_shap_values, -150)[-150:]\n",
    "#diff_shap_values[max_diff_shap_values_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3373eb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_arr, model_slist = sim.get_net_arr(model)\n",
    "model_arr[max_diff_shap_values_ind] = 0\n",
    "updated_model = sim.get_arr_net(model, model_arr, model_slist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "36e1159b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 7524/9556 (79%)\n",
      "\n",
      "2032 tensor([0]) tensor([0])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for inputs, target in test_loader:\n",
    "        outputs = updated_model(inputs)\n",
    "        pred = outputs.max(1, keepdim=True)[1] \n",
    "        correct = pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        accuracy = correct / len(inputs)\n",
    "        print('\\nAccuracy: {}/{} ({:.0f}%)\\n'.format(correct, len(inputs), 100. * accuracy))\n",
    "        \n",
    "\n",
    "Y_prob = F.softmax(outputs, dim=1)[:, 1]\n",
    "Y_pred = outputs.max(1, keepdim=True)[1]\n",
    "print(sum(Y_test), sum(Y_pred), sum(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39c508d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demographic parity difference: 0.221\n",
      "Demographic parity ratio: 0.000\n"
     ]
    }
   ],
   "source": [
    "dpd = demographic_parity_difference(\n",
    "    Y_test, Y_pred, sensitive_features=test_oh.NATIVITY,\n",
    ")\n",
    "dpr = demographic_parity_ratio(\n",
    "    Y_test, Y_pred, sensitive_features=test_oh.NATIVITY,\n",
    ")\n",
    "\n",
    "print(f\"Demographic parity difference: {dpd:.3f}\")\n",
    "print(f\"Demographic parity ratio: {dpr:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "946bca74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equalised odds difference: 0.360\n",
      "Equalised odds ratio: 0.000\n"
     ]
    }
   ],
   "source": [
    "eod = equalized_odds_difference(\n",
    "    Y_test, Y_pred, sensitive_features=test_oh.SEX,\n",
    ")\n",
    "eor = equalized_odds_ratio(\n",
    "    Y_test, Y_pred, sensitive_features=test_oh.SEX,\n",
    ")\n",
    "\n",
    "print(f\"Equalised odds difference: {eod:.3f}\")\n",
    "print(f\"Equalised odds ratio: {eor:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77048a81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:shap]",
   "language": "python",
   "name": "conda-env-shap-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
